{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aisles = pd.read_csv(\"aisles.csv\")\n",
    "#departments = pd.read_csv(\"departments.csv\")\n",
    "orders = pd.read_csv(\"orders.csv\")\n",
    "order_prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "order_train = pd.read_csv(\"order_products__train.csv\")\n",
    "#products = pd.read_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = orders.user_id[orders.eval_set=='train']\n",
    "data_train = orders[orders['user_id'].isin(users_train)]\n",
    "data_train.head()\n",
    "\n",
    "users_predict = orders.user_id[orders.eval_set=='test']\n",
    "data_predict = orders[orders['user_id'].isin(users_predict)]\n",
    "data_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.groupby('user_id').order_number.max().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_10 = data_train.user_id[data_train.order_number > 9]\n",
    "data_train = data_train[data_train['user_id'].isin(users_10)]\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_train = data_train.loc[(data_train.user_id==2) & (data_train.eval_set=='prior'),:]\n",
    "orders_train = pd.merge(orders_train,order_prior,'inner',on='order_id')\n",
    "orders_test = data_train.loc[(data_train.user_id==2) & (data_train.eval_set=='train'),:]\n",
    "orders_test = pd.merge(orders_test,order_train,'inner',on='order_id')\n",
    "print(orders_train.head())\n",
    "print(orders_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_days = orders_train[['order_number','days_since_prior_order']]\n",
    "order_days = order_days.drop_duplicates()\n",
    "order_days.update(order_days[['days_since_prior_order']].fillna(0))\n",
    "order_days['cum_days'] = order_days['days_since_prior_order'].cumsum() # not an accurate way of thinking about it.\n",
    "order_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_map = order_days.groupby('order_number').cum_days.mean().to_dict()\n",
    "orders_train['cum_days'] = orders_train.order_number.map(order_map)\n",
    "orders_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_map = orders_train.groupby('product_id').cum_days.max().to_dict()\n",
    "orders_train['recency'] = (orders_train.cum_days.max() - orders_train.product_id.map(recency_map)) / 7\n",
    "orders_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequency_map = orders_train['product_id'].value_counts().to_dict()\n",
    "orders_train['frequency'] = orders_train.product_id.map(frequency_map) / orders_train.order_number.max()\n",
    "orders_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_order_map = orders_train.groupby('product_id').add_to_cart_order.mean().to_dict()\n",
    "orders_train['cart_order'] = orders_train.product_id.map(cart_order_map) / \\\n",
    "                             orders_train.groupby('order_number').order_number.value_counts().mean()\n",
    "orders_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_train = orders_train[['product_id','recency','frequency','cart_order']].copy()\n",
    "orders_train = orders_train.drop_duplicates()\n",
    "orders_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_test['buy'] = 1\n",
    "orders_test = orders_test[['product_id','buy']]\n",
    "df = pd.merge(orders_train,orders_test,'left',on='product_id')\n",
    "df.update(df[['buy']].fillna(0))\n",
    "df = df.drop(['product_id'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rfm(user_ids):\n",
    "    frames = []\n",
    "    for user_id in user_ids:\n",
    "        orders_train = data_train.loc[(data_train.user_id==user_id) & (data_train.eval_set=='prior'),:]\n",
    "        orders_train = pd.merge(orders_train,order_prior,'inner',on='order_id')\n",
    "        orders_test = data_train.loc[(data_train.user_id==user_id) & (data_train.eval_set=='train'),:]\n",
    "        orders_test = pd.merge(orders_test,order_train,'inner',on='order_id')\n",
    "        frequency_map = orders_train['product_id'].value_counts().to_dict()\n",
    "        order_days = orders_train[['order_number','days_since_prior_order']]\n",
    "        order_days = order_days.drop_duplicates()\n",
    "        order_days.update(order_days[['days_since_prior_order']].fillna(0))\n",
    "        order_days['cum_days'] = order_days['days_since_prior_order'].cumsum()\n",
    "        order_map = order_days.groupby('order_number').cum_days.mean().to_dict()\n",
    "        orders_train['cum_days'] = orders_train.order_number.map(order_map)\n",
    "        recency_map = orders_train.groupby('product_id').cum_days.max().to_dict()\n",
    "        orders_train['recency'] = (orders_train.cum_days.max() - orders_train.product_id.map(recency_map)) / 7\n",
    "        orders_train['frequency'] = orders_train.product_id.map(frequency_map) / orders_train.order_number.max()\n",
    "        cart_order_map = orders_train.groupby('product_id').add_to_cart_order.mean().to_dict()\n",
    "        orders_train['cart_order'] = orders_train.product_id.map(cart_order_map) / \\\n",
    "                                     orders_train.groupby('order_number').order_number.value_counts().mean()\n",
    "        orders_train = orders_train[['product_id','recency','frequency','cart_order']].copy()\n",
    "        orders_train = orders_train.drop_duplicates()\n",
    "        orders_test['buy'] = 1\n",
    "        orders_test = orders_test[['product_id','buy']]\n",
    "        orders_comb = pd.merge(orders_train,orders_test,'left',on='product_id')\n",
    "        orders_comb.update(orders_comb[['buy']].fillna(0))\n",
    "        orders_comb = orders_comb.drop(['product_id'], axis = 1)\n",
    "        frames.append(orders_comb)\n",
    "    df = pd.concat(frames)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = data_train['user_id'].unique()\n",
    "user_ids = list(np.random.choice(users_train, 200))\n",
    "df = prepare_rfm(user_ids)\n",
    "df.buy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['recency','frequency','cart_order']\n",
    "X = df[features].copy()\n",
    "y = df['buy'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "logreg = LogisticRegression(class_weight={0:0.12})\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions = logreg.predict(X_test)\n",
    "y_proba = logreg.predict_proba(X_test)\n",
    "print('accuracy socre: ', accuracy_score(y_true = y_test, y_pred = predictions))\n",
    "print('auc: ', roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_test = data_predict.loc[data_predict.eval_set=='test',:]\n",
    "orders_test = orders_test.iloc[:200,]\n",
    "features = ['recency','frequency','cart_order']\n",
    "final = []\n",
    "for index, row in orders_test.iterrows():\n",
    "    orders_predict = data_predict.loc[(data_predict.user_id==row.user_id) & (data_predict.eval_set=='prior'),:]\n",
    "    orders_predict = pd.merge(orders_predict,order_prior,'inner',on='order_id')\n",
    "    frequency_map = orders_predict['product_id'].value_counts().to_dict()\n",
    "    order_days = orders_predict[['order_number','days_since_prior_order']]\n",
    "    order_days = order_days.drop_duplicates()\n",
    "    order_days.update(order_days[['days_since_prior_order']].fillna(0))\n",
    "    order_days['cum_days'] = order_days['days_since_prior_order'].cumsum()\n",
    "    order_map = order_days.groupby('order_number').cum_days.mean().to_dict()\n",
    "    orders_predict['cum_days'] = orders_predict.order_number.map(order_map)\n",
    "    recency_map = orders_predict.groupby('product_id').cum_days.max().to_dict()\n",
    "    orders_predict['recency'] = (orders_predict.cum_days.max() - orders_predict.product_id.map(recency_map)) / 7\n",
    "    orders_predict['frequency'] = orders_predict.product_id.map(frequency_map) / orders_predict.order_number.max()\n",
    "    cart_order_map = orders_predict.groupby('product_id').add_to_cart_order.mean().to_dict()\n",
    "    orders_predict['cart_order'] = orders_predict.product_id.map(cart_order_map) / \\\n",
    "                               orders_predict.groupby('order_number').order_number.value_counts().mean()\n",
    "    orders_predict = orders_predict[['product_id','recency','frequency','cart_order']].copy()\n",
    "    orders_predict = orders_predict.drop_duplicates()\n",
    "    df_predict = orders_predict.copy()\n",
    "    X = df_predict[features].copy()\n",
    "    y_proba = logreg.predict_proba(X)\n",
    "    df_pred = pd.DataFrame({\"product_id\":df_predict['product_id'],\"probability\":y_proba[:,1]})\n",
    "    df_pred = df_pred[df_pred.probability >= 0.5]\n",
    "    df_pred = df_pred.sort_values([\"probability\"], ascending = False)\n",
    "    ord_text = str(row['order_id'])\n",
    "    prods_text = \" \".join(str(x) for x in df_pred['product_id'].values)\n",
    "    submit_text = ord_text + \", \" + prods_text\n",
    "    final.append([submit_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
